{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from ..utils import load_state_dict_from_url\n",
    "\n",
    "\n",
    "__all__ = ['r3d_18', 'mc3_18', 'r2plus1d_18']\n",
    "\n",
    "model_urls = {\n",
    "    'r3d_18': 'https://download.pytorch.org/models/r3d_18-b3b3357e.pth',\n",
    "    'mc3_18': 'https://download.pytorch.org/models/mc3_18-a90a0ba3.pth',\n",
    "    'r2plus1d_18': 'https://download.pytorch.org/models/r2plus1d_18-91a641e6.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class Conv3DSimple(nn.Conv3d):\n",
    "    def __init__(self,\n",
    "                 in_planes,\n",
    "                 out_planes,\n",
    "                 midplanes=None,\n",
    "                 stride=1,\n",
    "                 padding=1):\n",
    "\n",
    "        super(Conv3DSimple, self).__init__(\n",
    "            in_channels=in_planes,\n",
    "            out_channels=out_planes,\n",
    "            kernel_size=(3, 3, 3),\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_downsample_stride(stride):\n",
    "        return stride, stride, stride\n",
    "\n",
    "\n",
    "class Conv2Plus1D(nn.Sequential):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_planes,\n",
    "                 out_planes,\n",
    "                 midplanes,\n",
    "                 stride=1,\n",
    "                 padding=1):\n",
    "        super(Conv2Plus1D, self).__init__(\n",
    "            nn.Conv3d(in_planes, midplanes, kernel_size=(1, 3, 3),\n",
    "                      stride=(1, stride, stride), padding=(0, padding, padding),\n",
    "                      bias=False),\n",
    "            nn.BatchNorm3d(midplanes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(midplanes, out_planes, kernel_size=(3, 1, 1),\n",
    "                      stride=(stride, 1, 1), padding=(padding, 0, 0),\n",
    "                      bias=False))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_downsample_stride(stride):\n",
    "        return stride, stride, stride\n",
    "\n",
    "\n",
    "class Conv3DNoTemporal(nn.Conv3d):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_planes,\n",
    "                 out_planes,\n",
    "                 midplanes=None,\n",
    "                 stride=1,\n",
    "                 padding=1):\n",
    "\n",
    "        super(Conv3DNoTemporal, self).__init__(\n",
    "            in_channels=in_planes,\n",
    "            out_channels=out_planes,\n",
    "            kernel_size=(1, 3, 3),\n",
    "            stride=(1, stride, stride),\n",
    "            padding=(0, padding, padding),\n",
    "            bias=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_downsample_stride(stride):\n",
    "        return 1, stride, stride\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, conv_builder, stride=1, downsample=None):\n",
    "        midplanes = (inplanes * planes * 3 * 3 * 3) // (inplanes * 3 * 3 + 3 * planes)\n",
    "\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            conv_builder(inplanes, planes, midplanes, stride),\n",
    "            nn.BatchNorm3d(planes),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            conv_builder(planes, planes, midplanes),\n",
    "            nn.BatchNorm3d(planes)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, conv_builder, stride=1, downsample=None):\n",
    "\n",
    "        super(Bottleneck, self).__init__()\n",
    "        midplanes = (inplanes * planes * 3 * 3 * 3) // (inplanes * 3 * 3 + 3 * planes)\n",
    "\n",
    "        # 1x1x1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(inplanes, planes, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm3d(planes),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Second kernel\n",
    "        self.conv2 = nn.Sequential(\n",
    "            conv_builder(planes, planes, midplanes, stride),\n",
    "            nn.BatchNorm3d(planes),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # 1x1x1\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(planes, planes * self.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm3d(planes * self.expansion)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BasicStem(nn.Sequential):\n",
    "    \"\"\"The default conv-batchnorm-relu stem\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BasicStem, self).__init__(\n",
    "            nn.Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2),\n",
    "                      padding=(1, 3, 3), bias=False),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "class R2Plus1dStem(nn.Sequential):\n",
    "    \"\"\"R(2+1)D stem is different than the default one as it uses separated 3D convolution\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(R2Plus1dStem, self).__init__(\n",
    "            nn.Conv3d(3, 45, kernel_size=(1, 7, 7),\n",
    "                      stride=(1, 2, 2), padding=(0, 3, 3),\n",
    "                      bias=False),\n",
    "            nn.BatchNorm3d(45),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(45, 64, kernel_size=(3, 1, 1),\n",
    "                      stride=(1, 1, 1), padding=(1, 0, 0),\n",
    "                      bias=False),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "class VideoResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, conv_makers, layers,\n",
    "                 stem, num_classes=400,\n",
    "                 zero_init_residual=False):\n",
    "        \"\"\"Generic resnet video generator.\n",
    "\n",
    "        Args:\n",
    "            block (nn.Module): resnet building block\n",
    "            conv_makers (list(functions)): generator function for each layer\n",
    "            layers (List[int]): number of blocks per layer\n",
    "            stem (nn.Module, optional): Resnet stem, if None, defaults to conv-bn-relu. Defaults to None.\n",
    "            num_classes (int, optional): Dimension of the final FC layer. Defaults to 400.\n",
    "            zero_init_residual (bool, optional): Zero init bottleneck residual BN. Defaults to False.\n",
    "        \"\"\"\n",
    "        super(VideoResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "\n",
    "        self.stem = stem()\n",
    "\n",
    "        self.layer1 = self._make_layer(block, conv_makers[0], 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, conv_makers[1], 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, conv_makers[2], 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, conv_makers[3], 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # init weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # Flatten the layer to fc\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, conv_builder, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            ds_stride = conv_builder.get_downsample_stride(stride)\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=ds_stride, bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, conv_builder, stride, downsample))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, conv_builder))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def _video_resnet(arch, pretrained=False, progress=True, **kwargs):\n",
    "    model = VideoResNet(**kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def r3d_18(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Construct 18 layer Resnet3D model as in\n",
    "    https://arxiv.org/abs/1711.11248\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on Kinetics-400\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: R3D-18 network\n",
    "    \"\"\"\n",
    "\n",
    "    return _video_resnet('r3d_18',\n",
    "                         pretrained, progress,\n",
    "                         block=BasicBlock,\n",
    "                         conv_makers=[Conv3DSimple] * 4,\n",
    "                         layers=[2, 2, 2, 2],\n",
    "                         stem=BasicStem, **kwargs)\n",
    "\n",
    "\n",
    "def mc3_18(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructor for 18 layer Mixed Convolution network as in\n",
    "    https://arxiv.org/abs/1711.11248\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on Kinetics-400\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: MC3 Network definition\n",
    "    \"\"\"\n",
    "    return _video_resnet('mc3_18',\n",
    "                         pretrained, progress,\n",
    "                         block=BasicBlock,\n",
    "                         conv_makers=[Conv3DSimple] + [Conv3DNoTemporal] * 3,\n",
    "                         layers=[2, 2, 2, 2],\n",
    "                         stem=BasicStem, **kwargs)\n",
    "\n",
    "\n",
    "def r2plus1d_18(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructor for the 18 layer deep R(2+1)D network as in\n",
    "    https://arxiv.org/abs/1711.11248\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on Kinetics-400\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: R(2+1)D-18 network\n",
    "    \"\"\"\n",
    "    return _video_resnet('r2plus1d_18',\n",
    "                         pretrained, progress,\n",
    "                         block=BasicBlock,\n",
    "                         conv_makers=[Conv2Plus1D] * 4,\n",
    "                         layers=[2, 2, 2, 2],\n",
    "                         stem=R2Plus1dStem, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
